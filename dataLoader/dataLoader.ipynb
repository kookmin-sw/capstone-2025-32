{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNjFVGhBf4zWTD/FETjAotp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install s2cloudless"],"metadata":{"id":"UBGbdpe95Yjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlQnDi5e4uBG"},"outputs":[],"source":["import numpy as np\n","import scipy\n","import scipy.signal as scisig\n","\n","\n","def rescale(data, limits):\n","    return (data - limits[0]) / (limits[1] - limits[0])\n","\n","\n","def normalized_difference(channel1, channel2):\n","    subchan = channel1 - channel2\n","    sumchan = channel1 + channel2\n","    sumchan[sumchan == 0] = 0.001  # checking for 0 divisions\n","    return subchan / sumchan\n","\n","\n","def get_shadow_mask(data_image):\n","    data_image = data_image / 10000.\n","\n","    (ch, r, c) = data_image.shape\n","    shadowmask = np.zeros((r, c)).astype('float32')\n","\n","    BB     = data_image[1]\n","    BNIR   = data_image[7]\n","    BSWIR1 = data_image[11]\n","\n","    CSI = (BNIR + BSWIR1) / 2.\n","\n","    t3 = 3/4 # cloud-score index threshold\n","    T3 = np.min(CSI) + t3 * (np.mean(CSI) - np.min(CSI))\n","\n","    t4 = 5 / 6  # water-body index threshold\n","    T4 = np.min(BB) + t4 * (np.mean(BB) - np.min(BB))\n","\n","    shadow_tf = np.logical_and(CSI < T3, BB < T4)\n","\n","    shadowmask[shadow_tf] = -1\n","    shadowmask = scisig.medfilt2d(shadowmask, 5)\n","\n","    return shadowmask\n","\n","\n","def get_cloud_mask(data_image, cloud_threshold, binarize=False, use_moist_check=False):\n","    '''Adapted from https://github.com/samsammurphy/cloud-masking-sentinel2/blob/master/cloud-masking-sentinel2.ipynb'''\n","\n","    data_image = data_image / 10000.\n","    (ch, r, c) = data_image.shape\n","\n","    # Cloud until proven otherwise\n","    score = np.ones((r, c)).astype('float32')\n","    # Clouds are reasonably bright in the blue and aerosol/cirrus bands.\n","    score = np.minimum(score, rescale(data_image[1], [0.1, 0.5]))\n","    score = np.minimum(score, rescale(data_image[0], [0.1, 0.3]))\n","    score = np.minimum(score, rescale((data_image[0] + data_image[10]), [0.4, 0.9]))\n","    score = np.minimum(score, rescale((data_image[3] + data_image[2] + data_image[1]), [0.2, 0.8]))\n","\n","    if use_moist_check:\n","        # Clouds are moist\n","        ndmi = normalized_difference(data_image[7], data_image[11])\n","        score = np.minimum(score, rescale(ndmi, [-0.1, 0.1]))\n","\n","    # However, clouds are not snow.\n","    ndsi = normalized_difference(data_image[2], data_image[11])\n","    score = np.minimum(score, rescale(ndsi, [0.8, 0.6]))\n","\n","    boxsize = 7\n","    box = np.ones((boxsize, boxsize)) / (boxsize ** 2)\n","\n","    score = scipy.ndimage.morphology.grey_closing(score, size=(5, 5))\n","    score = scisig.convolve2d(score, box, mode='same')\n","\n","    score = np.clip(score, 0.00001, 1.0)\n","\n","    if binarize:\n","        score[score >= cloud_threshold] = 1\n","        score[score < cloud_threshold]  = 0\n","\n","    return score\n","\n","# IN: [13 x H x W] S2 image (of arbitrary resolution H,W), scalar cloud detection threshold\n","# OUT: cloud & shadow segmentation mask (of same resolution)\n","# the multispectral S2 images are expected to have their default ranges and not be value-standardized yet\n","# cloud_threshold: the higher the more conservative the masks (i.e. less pixels labeled clouds/shadows)\n","def get_cloud_cloudshadow_mask(data_image, cloud_threshold):\n","    cloud_mask = get_cloud_mask(data_image, cloud_threshold, binarize=True)\n","    shadow_mask = get_shadow_mask(data_image)\n","\n","    # encode clouds and shadows as segmentation masks\n","    cloud_cloudshadow_mask = np.zeros_like(cloud_mask)\n","    cloud_cloudshadow_mask[shadow_mask < 0] = -1\n","    cloud_cloudshadow_mask[cloud_mask > 0]  = 1\n","\n","    return cloud_cloudshadow_mask"]},{"cell_type":"code","source":["import os\n","import warnings\n","import numpy as np\n","from tqdm import tqdm\n","from natsort import natsorted\n","\n","from datetime import datetime\n","to_date   = lambda string: datetime.strptime(string, '%Y-%m-%d')\n","S1_LAUNCH = to_date('2014-04-03')\n","\n","import rasterio\n","from scipy.ndimage import gaussian_filter\n","from torch.utils.data import Dataset\n","\n","# s2cloudless: see https://github.com/sentinel-hub/sentinel2-cloud-detector\n","from s2cloudless import S2PixelCloudDetector\n","# from util.detect_cloudshadow import get_cloud_mask, get_shadow_mask\n","# code를 직접 가져와서 해결, Masking 안하는 경우에는 사용하지 않더라도 괜찮을 것으로 보임\n","\n","\n","# utility functions used in the dataloaders of SEN12MS-CR and SEN12MS-CR-TS\n","def read_tif(path_IMG):  # 경로 탐색\n","    tif = rasterio.open(path_IMG)\n","    return tif\n","\n","def read_img(tif):  # 해당 경로의 tif 이미지 읽기(float32)\n","    return tif.read().astype(np.float32)\n","\n","def rescale(img, oldMin, oldMax):  # 사이즈 noramlizing\n","    oldRange = oldMax - oldMin\n","    img      = (img - oldMin) / oldRange\n","    return img\n","\n","def process_MS(img, method):                               # \"SEN12MS-CR-TS\" , Multi-spectral\n","    if method=='default':\n","        intensity_min, intensity_max = 0, 10000            # define a reasonable range of MS intensities\n","        img = np.clip(img, intensity_min, intensity_max)   # intensity clipping to a global unified MS intensity range\n","        img = rescale(img, intensity_min, intensity_max)   # project to [0,1], preserve global intensities (across patches), gets mapped to [-1,+1] in wrapper\n","    if method=='resnet':\n","        intensity_min, intensity_max = 0, 10000            # define a reasonable range of MS intensities\n","        img = np.clip(img, intensity_min, intensity_max)   # intensity clipping to a global unified MS intensity range\n","        img /= 2000                                        # project to [0,5], preserve global intensities (across patches)\n","    return img\n","\n","def process_SAR(img, method):\n","    if method=='default':\n","        dB_min, dB_max = -25, 0                            # define a reasonable range of SAR dB\n","        img = np.clip(img, dB_min, dB_max)                 # intensity clipping to a global unified SAR dB range\n","        img = rescale(img, dB_min, dB_max)                 # project to [0,1], preserve global intensities (across patches), gets mapped to [-1,+1] in wrapper\n","    if method=='resnet':\n","        # project SAR to [0, 2] range\n","        dB_min, dB_max = [-25.0, -32.5], [0, 0]\n","        img = np.concatenate([(2 * (np.clip(img[0], dB_min[0], dB_max[0]) - dB_min[0]) / (dB_max[0] - dB_min[0]))[None, ...],\n","                              (2 * (np.clip(img[1], dB_min[1], dB_max[1]) - dB_min[1]) / (dB_max[1] - dB_min[1]))[None, ...]], axis=0)\n","    return img\n","\n","def get_cloud_cloudshadow_mask(img, cloud_threshold=0.2):  # cloud + shadow 부분에 대한 masking 정보 추출하기(다른 algorithm 이용), Masking 정보를 이용하지 않는 경우 필요 X\n","    cloud_mask = get_cloud_mask(img, cloud_threshold, binarize=True)\n","    shadow_mask = get_shadow_mask(img)\n","\n","    # encode clouds and shadows as segmentation masks\n","    cloud_cloudshadow_mask = np.zeros_like(cloud_mask)\n","    cloud_cloudshadow_mask[shadow_mask < 0] = -1\n","    cloud_cloudshadow_mask[cloud_mask > 0] = 1\n","\n","    # label clouds and shadows\n","    cloud_cloudshadow_mask[cloud_cloudshadow_mask != 0] = 1\n","    return cloud_cloudshadow_mask\n","\n","def get_cloud_map(img, detector, instance=None):\n","\n","    if detector == 'cloud_cloudshadow_mask':\n","        threshold = 0.2  # set to e.g. 0.2 or 0.4\n","        mask = get_cloud_cloudshadow_mask(np.clip(img, 0, 10000), threshold)\n","    elif detector== 's2cloudless_map':\n","        threshold = 0.5\n","        mask = instance.get_cloud_probability_maps(np.moveaxis(np.clip(img, 0, 10000)/10000, 0, -1)[None, ...])[0, ...]\n","        mask[mask < threshold] = 0\n","        mask = gaussian_filter(mask, sigma=2).astype(np.float32)\n","    elif detector == 's2cloudless_mask':\n","        mask = instance.get_cloud_masks(np.moveaxis(np.clip(img, 0, 10000)/10000, 0, -1)[None, ...])[0, ...]\n","    else:\n","        mask = np.ones((img.shape[-1], img.shape[-1]))\n","    return mask\n","\n","\n","\"\"\" SEN12MSCRTS data loader class, inherits from torch.utils.data.Dataset\n","\n","    IN:\n","    root:               str, path to your copy of the SEN12MS-CR-TS data set\n","    split:              str, in [all | train | val | test]\n","    region:             str, [all | africa | america | asiaEast | asiaWest | europa]\n","    cloud_masks:        str, type of cloud mask detector to run on optical data, in []\n","    sample_type:        str, [generic | cloudy_cloudfree]\n","    n_input_samples:    int, number of input samples in time series\n","    rescale_method:     str, [default | resnet]\n","    min_cov:            float, in [0.0, 1.0]\n","    max_cov:            float, in [0.0, 1.0]\n","    import_data_path:   str, path to importing the suppl. file specifying what time points to load for input and output\n","    export_data_path:   str, path to export the suppl. file specifying what time points to load for input and output\n","\n","    OUT:\n","    data_loader:        SEN12MSCRTS instance, implements an iterator that can be traversed via __getitem__(pdx),\n","                        which returns the pdx-th dictionary of patch-samples (whose structure depends on sample_type)\n","\"\"\"\n","\n","class SEN12MSCRTS(Dataset):\n","    def __init__(self, root, split=\"all\", region='all', cloud_masks='s2cloudless_mask', sample_type='cloudy_cloudfree', n_input_samples=3, rescale_method='default', min_cov=0.0, max_cov=1.0, import_data_path=None, export_data_path=None):\n","\n","        self.root_dir = root   # set root directory which contains all ROI\n","        self.region   = region # region according to which the ROI are selected\n","        self.ROI      = {'ROIs1158': ['106'],\n","                         'ROIs1868': ['17', '36', '56', '73', '85', '100', '114', '119', '121', '126', '127', '139', '142', '143'],\n","                         'ROIs1970': ['20', '21', '35', '40', '57', '65', '71', '82', '83', '91', '112', '116', '119', '128', '132', '133', '135', '139', '142', '144', '149'],\n","                         'ROIs2017': ['8', '22', '25', '32', '49', '61', '63', '69', '75', '103', '108', '115', '116', '117', '130', '140', '146']}\n","\n","        # define splits conform with SEN12MS-CR, e.g. os.path.join('ROIs1868', '119') -> ROIs1868\\119 -> shell script로 다운받는 경우, 구조에 대해서 수정할 필요는 없어보입니다.\n","        self.splits         = {}\n","        if self.region=='all':\n","            all_ROI             = [os.path.join(key, val) for key, vals in self.ROI.items() for val in vals]\n","            self.splits['test'] = [os.path.join('ROIs1868', '119'), os.path.join('ROIs1970', '139'), os.path.join('ROIs2017', '108'), os.path.join('ROIs2017', '63'), os.path.join('ROIs1158', '106'), os.path.join('ROIs1868', '73'), os.path.join('ROIs2017', '32'),\n","                                   os.path.join('ROIs1868', '100'), os.path.join('ROIs1970', '132'), os.path.join('ROIs2017', '103'), os.path.join('ROIs1868', '142'), os.path.join('ROIs1970', '20'), os.path.join('ROIs2017', '140')]  # official test split, across continents\n","            self.splits['val']  = [os.path.join('ROIs2017', '22'), os.path.join('ROIs1970', '65'), os.path.join('ROIs2017', '117'), os.path.join('ROIs1868', '127'), os.path.join('ROIs1868', '17')] # insert a validation split here\n","            self.splits['train']= [roi for roi in all_ROI if roi not in self.splits['val'] and roi not in self.splits['test']]  # all remaining ROI are used for training\n","        elif self.region=='africa':\n","            self.splits['test'] = [os.path.join('ROIs2017', '32'), os.path.join('ROIs2017', '140')]\n","            self.splits['val']  = [os.path.join('ROIs2017', '22')]\n","            self.splits['train']= [os.path.join('ROIs1970', '21'), os.path.join('ROIs1970', '35'), os.path.join('ROIs1970', '40'),\n","                                   os.path.join('ROIs2017', '8'), os.path.join('ROIs2017', '61'), os.path.join('ROIs2017', '75')]\n","        elif self.region=='america':\n","            self.splits['test'] = [os.path.join('ROIs1158', '106'), os.path.join('ROIs1970', '132')]\n","            self.splits['val']  = [os.path.join('ROIs1970', '65')]\n","            self.splits['train']= [os.path.join('ROIs1868', '36'), os.path.join('ROIs1868', '85'),\n","                                   os.path.join('ROIs1970', '82'), os.path.join('ROIs1970', '142'),\n","                                   os.path.join('ROIs2017', '49'), os.path.join('ROIs2017', '116')]\n","        elif self.region=='asiaEast':\n","            self.splits['test'] = [os.path.join('ROIs1868', '73'), os.path.join('ROIs1868', '119'), os.path.join('ROIs1970', '139')]\n","            self.splits['val']  = [os.path.join('ROIs2017', '117')]\n","            self.splits['train']= [os.path.join('ROIs1868', '114'), os.path.join('ROIs1868', '126'), os.path.join('ROIs1868', '143'),\n","                                   os.path.join('ROIs1970', '116'), os.path.join('ROIs1970', '135'),\n","                                   os.path.join('ROIs2017', '25')]\n","        elif self.region=='asiaWest':\n","            self.splits['test'] = [os.path.join('ROIs1868', '100')]\n","            self.splits['val']  = [os.path.join('ROIs1868', '127')]\n","            self.splits['train']= [os.path.join('ROIs1970', '57'), os.path.join('ROIs1970', '83'), os.path.join('ROIs1970', '112'),\n","                                   os.path.join('ROIs2017', '69'), os.path.join('ROIs1970', '115'), os.path.join('ROIs1970', '130')]\n","        elif self.region=='europa':\n","            self.splits['test'] = [os.path.join('ROIs2017', '63'), os.path.join('ROIs2017', '103'), os.path.join('ROIs2017', '108'), os.path.join('ROIs1868', '142'), os.path.join('ROIs1970', '20')]\n","            self.splits['val']  = [os.path.join('ROIs1868', '17')]\n","            self.splits['train']= [os.path.join('ROIs1868', '56'), os.path.join('ROIs1868', '121'), os.path.join('ROIs1868', '139'),\n","                                   os.path.join('ROIs1970', '71'), os.path.join('ROIs1970', '91'), os.path.join('ROIs1970', '119'), os.path.join('ROIs1970', '128'), os.path.join('ROIs1970', '133'), os.path.join('ROIs1970', '144'), os.path.join('ROIs1970', '149'),\n","                                   os.path.join('ROIs2017', '146')]\n","        else: raise NotImplementedError\n","\n","        self.splits[\"all\"]  = self.splits[\"train\"] + self.splits[\"test\"] + self.splits[\"val\"]\n","        self.split = split\n","\n","        assert split in ['all', 'train', 'val', 'test'], \"Input dataset must be either assigned as all, train, test, or val!\"\n","        assert sample_type in ['generic', 'cloudy_cloudfree'], \"Input data must be either generic or cloudy_cloudfree type!\"\n","        assert cloud_masks in [None, 'cloud_cloudshadow_mask', 's2cloudless_map', 's2cloudless_mask'], \"Unknown cloud mask type!\"\n","\n","        self.modalities     = [\"S1\", \"S2\"]\n","        self.time_points    = range(30)    # time-series에 대한 정보\n","        self.cloud_masks    = cloud_masks  # e.g. 'cloud_cloudshadow_mask', 's2cloudless_map', 's2cloudless_mask'\n","        self.sample_type    = sample_type if self.cloud_masks is not None else 'generic' # pick 'generic' or 'cloudy_cloudfree'\n","        self.n_input_t      = n_input_samples  # specifies the number of samples, if only part of the time series is used as an input\n","\n","        if self.cloud_masks in ['s2cloudless_map', 's2cloudless_mask']:\n","            self.cloud_detector = S2PixelCloudDetector(threshold=0.4, all_bands=True, average_over=4, dilation_size=2)\n","        else: self.cloud_detector = None\n","\n","        self.import_data_path = import_data_path\n","        self.export_data_path = export_data_path\n","        if self.export_data_path: self.data_pairs = {}\n","\n","        if self.import_data_path:\n","            # fetch time points as specified in the imported file, expects arguments are set accordingly\n","            if os.path.isdir(self.import_data_path):\n","                import_here = os.path.join(self.import_data_path, f'{self.n_input_t}_{self.split}_{self.cloud_masks}.npy')\n","            else:\n","                import_here = self.import_data_path\n","            self.data_pairs = np.load(import_here, allow_pickle=True).item()\n","            print(f'Importing data pairings for split {self.split} from {import_here}.')\n","\n","        self.paths          = self.get_paths()\n","        self.n_samples      = len(self.paths)\n","\n","        # raise a warning that no data has been found\n","        if not self.n_samples: self.throw_warn()\n","\n","        self.method         = rescale_method\n","        self.min_cov, self.max_cov = min_cov, max_cov\n","\n","    def throw_warn(self):\n","        warnings.warn(\"\"\"No data samples found! Please use the following directory structure:\n","\n","        path/to/your/SEN12MSCRTS/directory:\n","        ├───ROIs1158\n","        ├───ROIs1868\n","        ├───ROIs1970\n","        │   ├───20\n","        │   ├───21\n","        │   │   ├───S1\n","        │   │   └───S2\n","        │   │       ├───0\n","        │   │       ├───1\n","        │   │       │   └─── ... *.tif files\n","        │   │       └───30\n","        │   ...\n","        └───ROIs2017\n","\n","        Note: the data is provided by ROI geo-spatially separated and sensor modalities individually.\n","        You can simply merge the downloaded & extracted archives' subdirectories via 'mv */* .' in the parent directory\n","        to obtain the required structure specified above, which the data loader expects.\n","        \"\"\")\n","\n","    # indexes all patches contained in the current data split\n","    def get_paths(self):  # assuming for the same ROI+num, the patch numbers are the same\n","        print(f'\\nProcessing paths for {self.split} split of region {self.region}')\n","\n","        paths = []\n","        for roi_dir, rois in self.ROI.items():\n","            for roi in tqdm(rois):\n","                roi_path = os.path.join(self.root_dir, roi_dir, roi)\n","                # skip non-existent ROI or ROI not part of the current data split\n","                if not os.path.isdir(roi_path) or os.path.join(roi_dir, roi) not in self.splits[self.split]: continue\n","                path_s1_t, path_s2_t = [], [],\n","                for tdx in self.time_points:\n","                    # working with directory under time stamp tdx\n","                    path_s1_complete = os.path.join(roi_path, self.modalities[0], str(tdx))\n","                    path_s2_complete = os.path.join(roi_path, self.modalities[1], str(tdx))\n","\n","                    # same as complete paths, truncating root directory's path\n","                    path_s1 = os.path.join(roi_dir, roi, self.modalities[0], str(tdx))\n","                    path_s2 = os.path.join(roi_dir, roi, self.modalities[1], str(tdx))\n","\n","                    # get list of files which contains all the patches at time tdx\n","                    s1_t = natsorted([os.path.join(path_s1, f) for f in os.listdir(path_s1_complete) if (os.path.isfile(os.path.join(path_s1_complete, f)) and \".tif\" in f)])\n","                    s2_t = natsorted([os.path.join(path_s2, f) for f in os.listdir(path_s2_complete) if (os.path.isfile(os.path.join(path_s2_complete, f)) and \".tif\" in f)])\n","\n","                    # same number of patches\n","                    assert len(s1_t) == len(s2_t)\n","\n","                    # sort via file names according to patch number and store\n","                    path_s1_t.append(s1_t)\n","                    path_s2_t.append(s2_t)\n","\n","                # for each patch of the ROI, collect its time points and make this one sample\n","                for pdx in range(len(path_s1_t[0])):\n","                    sample = {\"S1\": [path_s1_t[tdx][pdx] for tdx in self.time_points],\n","                              \"S2\": [path_s2_t[tdx][pdx] for tdx in self.time_points]}\n","                    paths.append(sample)\n","\n","        return paths\n","\n","    def __getitem__(self, pdx):  # get the time series of one patch\n","\n","        # get images\n","        s1_tif          = [read_tif(os.path.join(self.root_dir, img)) for img in self.paths[pdx]['S1']]\n","        s2_tif          = [read_tif(os.path.join(self.root_dir, img)) for img in self.paths[pdx]['S2']]\n","        coord           = [list(tif.bounds) for tif in s2_tif]\n","        s1              = [process_SAR(read_img(img), self.method) for img in s1_tif]\n","        s2              = [read_img(img) for img in s2_tif]  # note: pre-processing happens after cloud detection\n","        masks           = None if not self.cloud_masks else [get_cloud_map(img, self.cloud_masks, self.cloud_detector) for img in s2]\n","\n","        # get statistics and additional meta information\n","        coverage    = [np.mean(mask) for mask in masks]\n","        s1_dates    = [to_date(img.split('/')[-1].split('_')[5]) for img in self.paths[pdx]['S1']]\n","        s2_dates    = [to_date(img.split('/')[-1].split('_')[5]) for img in self.paths[pdx]['S2']]\n","        s1_td       = [(date-S1_LAUNCH).days for date in s1_dates]\n","        s2_td       = [(date-S1_LAUNCH).days for date in s2_dates]\n","\n","        # generate data of ((cloudy_t1, cloudy_t2, ..., cloudy_tn), cloud-free) pairings\n","        # note: filtering the data (e.g. according to cloud coverage etc) and may only use a fraction of the data set\n","        #       if you wish to train or test on additional samples, then this filtering needs to be adjusted\n","        if self.sample_type == 'cloudy_cloudfree':\n","            if self.import_data_path:\n","                # read indices\n","                inputs_idx    = self.data_pairs[pdx]['input']\n","                cloudless_idx = self.data_pairs[pdx]['target']\n","                target_s1, target_s2, target_mask = np.array(s1)[cloudless_idx], np.array(s2)[cloudless_idx], np.array(masks)[cloudless_idx]\n","                input_s1, input_s2, input_masks   = np.array(s1)[inputs_idx], np.array(s2)[inputs_idx], np.array(masks)[inputs_idx]\n","                coverage_match = True\n","\n","            else:  # sample custom time points from the current patch space in the current split\n","                # sort observation indices according to cloud coverage, ascendingly\n","                coverage_idx = np.argsort(coverage)\n","                cloudless_idx = coverage_idx[0]\n","                # take the (earliest, in case of draw) least cloudy time point as target\n","                target_s1, target_s2, target_mask = np.array(s1)[cloudless_idx], np.array(s2)[cloudless_idx], np.array(masks)[cloudless_idx]\n","                # take the first n_input_t samples with cloud coverage e.g. in [0.1, 0.5], ...\n","                inputs_idx = [pdx for pdx, perc in enumerate(coverage) if perc >= self.min_cov and perc <= self.max_cov][:self.n_input_t]\n","                coverage_match = True  # assume the requested amount of cloud coverage is met\n","\n","                if len(inputs_idx) < self.n_input_t:\n","                    # ... if not exists then take the first n_input_t samples (except target patch)\n","                    inputs_idx = [pdx for pdx in range(len(coverage)) if pdx!=cloudless_idx][:self.n_input_t]\n","                    coverage_match = False  # flag input samples that didn't meet the required cloud coverage\n","                input_s1, input_s2, input_masks = np.array(s1)[inputs_idx], np.array(s2)[inputs_idx], np.array(masks)[inputs_idx]\n","\n","                if self.export_data_path:\n","                    # performs repeated writing to file, only use this for processes dedicated for exporting\n","                    # and if so, only use a single thread of workers (--num_threads 1), this ain't thread-safe\n","                    self.data_pairs[pdx] = {'input': inputs_idx, 'target': cloudless_idx,\n","                                            'paths': {'input': {'S1': [self.paths[pdx]['S1'][idx] for idx in inputs_idx],\n","                                                                'S2': [self.paths[pdx]['S2'][idx] for idx in inputs_idx]},\n","                                                      'output': {'S1': self.paths[pdx]['S1'][cloudless_idx],\n","                                                                 'S2': self.paths[pdx]['S2'][cloudless_idx]}}}\n","                    if os.path.isdir(self.export_data_path):\n","                        export_here = os.path.join(self.export_data_path, f'{self.n_input_t}_{self.split}_{self.cloud_masks}.npy')\n","                    else:\n","                        export_here = self.export_data_path\n","                    np.save(export_here, self.data_pairs)\n","\n","            sample = {'input': {'S1': list(input_s1),\n","                                'S2': [process_MS(img, self.method) for img in input_s2],\n","                                'masks': list(input_masks),\n","                                'coverage': [np.mean(mask) for mask in input_masks],\n","                                'S1 TD': [s1_td[idx] for idx in inputs_idx],\n","                                'S2 TD': [s2_td[idx] for idx in inputs_idx],\n","                                'S1 path': [os.path.join(self.root_dir, self.paths[pdx]['S1'][idx]) for idx in inputs_idx],\n","                                'S2 path': [os.path.join(self.root_dir, self.paths[pdx]['S2'][idx]) for idx in inputs_idx],\n","                                'coord': [coord[idx] for idx in inputs_idx],\n","                                },\n","                      'target': {'S1': [target_s1],\n","                                 'S2': [process_MS(target_s2, self.method)],\n","                                 'masks': [target_mask],\n","                                 'coverage': [np.mean(target_mask)],\n","                                 'S1 TD': [s1_td[cloudless_idx]],\n","                                 'S2 TD': [s2_td[cloudless_idx]],\n","                                 'S1 path': [os.path.join(self.root_dir, self.paths[pdx]['S1'][cloudless_idx])],\n","                                 'S2 path': [os.path.join(self.root_dir, self.paths[pdx]['S2'][cloudless_idx])],\n","                                 'coord': [coord[cloudless_idx]],\n","                                 },\n","                       'coverage bin': coverage_match\n","                      }\n","\n","        elif self.sample_type == 'generic':  # this returns the whole, unfiltered sequence of S1 & S2 observations\n","            sample = {'S1': s1,\n","                      'S2': [process_MS(img, self.method) for img in s2],\n","                      'masks': masks,\n","                      'coverage': coverage,\n","                      'S1 TD': s1_td,\n","                      'S2 TD': s2_td,\n","                      'S1 path': [os.path.join(self.root_dir, self.paths[pdx]['S1'][idx]) for idx in self.time_points],\n","                      'S2 path': [os.path.join(self.root_dir, self.paths[pdx]['S2'][idx]) for idx in self.time_points],\n","                      'coord': coord\n","                      }\n","        return sample\n","\n","    def __len__(self):\n","        # length of generated list\n","        return self.n_samples\n","\n","\n","\n","\"\"\" SEN12MSCR data loader class, inherits from torch.utils.data.Dataset\n","\n","    IN:\n","    root:               str, path to your copy of the SEN12MS-CR-TS data set\n","    split:              str, in [all | train | val | test]\n","    region:             str, [all | africa | america | asiaEast | asiaWest | europa]\n","    cloud_masks:        str, type of cloud mask detector to run on optical data, in []\n","    sample_type:        str, [generic | cloudy_cloudfree]\n","    n_input_samples:    int, number of input samples in time series\n","    rescale_method:     str, [default | resnet]\n","\n","    OUT:\n","    data_loader:        SEN12MSCRTS instance, implements an iterator that can be traversed via __getitem__(pdx),\n","                        which returns the pdx-th dictionary of patch-samples (whose structure depends on sample_type)\n","\"\"\"\n","\n","class SEN12MSCR(Dataset):\n","    def __init__(self, root, split=\"all\", region='all', cloud_masks='s2cloudless_mask', sample_type='pretrain', rescale_method='default'):\n","\n","        self.root_dir = root   # set root directory which contains all ROI\n","        self.region   = region # region according to which the ROI are selected # TODO: currently only supporting 'all'\n","        self.ROI      = {'ROIs1158': ['106'],\n","                         'ROIs1868': ['17', '36', '56', '73', '85', '100', '114', '119', '121', '126', '127', '139', '142', '143'],\n","                         'ROIs1970': ['20', '21', '35', '40', '57', '65', '71', '82', '83', '91', '112', '116', '119', '128', '132', '133', '135', '139', '142', '144', '149'],\n","                         'ROIs2017': ['8', '22', '25', '32', '49', '61', '63', '69', '75', '103', '108', '115', '116', '117', '130', '140', '146']}\n","\n","        # define splits conform with SEN12MS-CR-TS\n","        self.splits         = {}\n","        self.splits['train']= ['ROIs1970_fall_s1/s1_3', 'ROIs1970_fall_s1/s1_22', 'ROIs1970_fall_s1/s1_148', 'ROIs1970_fall_s1/s1_107', 'ROIs1970_fall_s1/s1_1', 'ROIs1970_fall_s1/s1_114',\n","                               'ROIs1970_fall_s1/s1_135', 'ROIs1970_fall_s1/s1_40', 'ROIs1970_fall_s1/s1_42', 'ROIs1970_fall_s1/s1_31', 'ROIs1970_fall_s1/s1_149', 'ROIs1970_fall_s1/s1_64',\n","                               'ROIs1970_fall_s1/s1_28', 'ROIs1970_fall_s1/s1_144', 'ROIs1970_fall_s1/s1_57', 'ROIs1970_fall_s1/s1_35', 'ROIs1970_fall_s1/s1_133', 'ROIs1970_fall_s1/s1_30',\n","                               'ROIs1970_fall_s1/s1_134', 'ROIs1970_fall_s1/s1_141', 'ROIs1970_fall_s1/s1_112', 'ROIs1970_fall_s1/s1_116', 'ROIs1970_fall_s1/s1_37', 'ROIs1970_fall_s1/s1_26',\n","                               'ROIs1970_fall_s1/s1_77', 'ROIs1970_fall_s1/s1_100', 'ROIs1970_fall_s1/s1_83', 'ROIs1970_fall_s1/s1_71', 'ROIs1970_fall_s1/s1_93', 'ROIs1970_fall_s1/s1_119',\n","                               'ROIs1970_fall_s1/s1_104', 'ROIs1970_fall_s1/s1_136', 'ROIs1970_fall_s1/s1_6', 'ROIs1970_fall_s1/s1_41', 'ROIs1970_fall_s1/s1_125', 'ROIs1970_fall_s1/s1_91',\n","                               'ROIs1970_fall_s1/s1_131', 'ROIs1970_fall_s1/s1_120', 'ROIs1970_fall_s1/s1_110', 'ROIs1970_fall_s1/s1_19', 'ROIs1970_fall_s1/s1_14', 'ROIs1970_fall_s1/s1_81',\n","                               'ROIs1970_fall_s1/s1_39', 'ROIs1970_fall_s1/s1_109', 'ROIs1970_fall_s1/s1_33', 'ROIs1970_fall_s1/s1_88', 'ROIs1970_fall_s1/s1_11', 'ROIs1970_fall_s1/s1_128',\n","                               'ROIs1970_fall_s1/s1_142', 'ROIs1970_fall_s1/s1_122', 'ROIs1970_fall_s1/s1_4', 'ROIs1970_fall_s1/s1_27', 'ROIs1970_fall_s1/s1_147', 'ROIs1970_fall_s1/s1_85',\n","                               'ROIs1970_fall_s1/s1_82', 'ROIs1970_fall_s1/s1_105', 'ROIs1158_spring_s1/s1_9', 'ROIs1158_spring_s1/s1_1', 'ROIs1158_spring_s1/s1_124', 'ROIs1158_spring_s1/s1_40',\n","                               'ROIs1158_spring_s1/s1_101', 'ROIs1158_spring_s1/s1_21', 'ROIs1158_spring_s1/s1_134', 'ROIs1158_spring_s1/s1_145', 'ROIs1158_spring_s1/s1_141', 'ROIs1158_spring_s1/s1_66',\n","                               'ROIs1158_spring_s1/s1_8', 'ROIs1158_spring_s1/s1_26', 'ROIs1158_spring_s1/s1_77', 'ROIs1158_spring_s1/s1_113', 'ROIs1158_spring_s1/s1_100',\n","                               'ROIs1158_spring_s1/s1_117', 'ROIs1158_spring_s1/s1_119', 'ROIs1158_spring_s1/s1_6', 'ROIs1158_spring_s1/s1_58', 'ROIs1158_spring_s1/s1_120', 'ROIs1158_spring_s1/s1_110',\n","                               'ROIs1158_spring_s1/s1_126', 'ROIs1158_spring_s1/s1_115', 'ROIs1158_spring_s1/s1_121', 'ROIs1158_spring_s1/s1_39', 'ROIs1158_spring_s1/s1_109', 'ROIs1158_spring_s1/s1_63',\n","                               'ROIs1158_spring_s1/s1_75', 'ROIs1158_spring_s1/s1_132', 'ROIs1158_spring_s1/s1_128', 'ROIs1158_spring_s1/s1_142', 'ROIs1158_spring_s1/s1_15', 'ROIs1158_spring_s1/s1_45',\n","                               'ROIs1158_spring_s1/s1_97', 'ROIs1158_spring_s1/s1_147', 'ROIs1868_summer_s1/s1_90', 'ROIs1868_summer_s1/s1_87', 'ROIs1868_summer_s1/s1_25', 'ROIs1868_summer_s1/s1_124',\n","                               'ROIs1868_summer_s1/s1_114', 'ROIs1868_summer_s1/s1_135', 'ROIs1868_summer_s1/s1_40', 'ROIs1868_summer_s1/s1_101', 'ROIs1868_summer_s1/s1_42',\n","                               'ROIs1868_summer_s1/s1_31', 'ROIs1868_summer_s1/s1_36', 'ROIs1868_summer_s1/s1_139', 'ROIs1868_summer_s1/s1_56', 'ROIs1868_summer_s1/s1_133', 'ROIs1868_summer_s1/s1_55',\n","                               'ROIs1868_summer_s1/s1_43', 'ROIs1868_summer_s1/s1_113', 'ROIs1868_summer_s1/s1_100', 'ROIs1868_summer_s1/s1_76', 'ROIs1868_summer_s1/s1_123', 'ROIs1868_summer_s1/s1_143',\n","                               'ROIs1868_summer_s1/s1_93', 'ROIs1868_summer_s1/s1_125', 'ROIs1868_summer_s1/s1_89', 'ROIs1868_summer_s1/s1_120', 'ROIs1868_summer_s1/s1_126', 'ROIs1868_summer_s1/s1_72',\n","                               'ROIs1868_summer_s1/s1_115', 'ROIs1868_summer_s1/s1_121', 'ROIs1868_summer_s1/s1_146', 'ROIs1868_summer_s1/s1_140', 'ROIs1868_summer_s1/s1_95',\n","                               'ROIs1868_summer_s1/s1_102', 'ROIs1868_summer_s1/s1_7', 'ROIs1868_summer_s1/s1_11', 'ROIs1868_summer_s1/s1_132', 'ROIs1868_summer_s1/s1_15', 'ROIs1868_summer_s1/s1_137',\n","                               'ROIs1868_summer_s1/s1_4', 'ROIs1868_summer_s1/s1_27', 'ROIs1868_summer_s1/s1_147', 'ROIs1868_summer_s1/s1_86', 'ROIs1868_summer_s1/s1_47', 'ROIs2017_winter_s1/s1_68',\n","                               'ROIs2017_winter_s1/s1_25', 'ROIs2017_winter_s1/s1_62', 'ROIs2017_winter_s1/s1_135', 'ROIs2017_winter_s1/s1_42', 'ROIs2017_winter_s1/s1_64', 'ROIs2017_winter_s1/s1_21',\n","                               'ROIs2017_winter_s1/s1_55', 'ROIs2017_winter_s1/s1_112', 'ROIs2017_winter_s1/s1_116', 'ROIs2017_winter_s1/s1_8', 'ROIs2017_winter_s1/s1_59', 'ROIs2017_winter_s1/s1_49',\n","                               'ROIs2017_winter_s1/s1_104',  'ROIs2017_winter_s1/s1_81', 'ROIs2017_winter_s1/s1_146', 'ROIs2017_winter_s1/s1_75',\n","                               'ROIs2017_winter_s1/s1_94', 'ROIs2017_winter_s1/s1_102', 'ROIs2017_winter_s1/s1_61', 'ROIs2017_winter_s1/s1_47']\n","        self.splits['val']  = ['ROIs2017_winter_s1/s1_22', 'ROIs1868_summer_s1/s1_19', 'ROIs1970_fall_s1/s1_65', 'ROIs1158_spring_s1/s1_17', 'ROIs2017_winter_s1/s1_107',\n","                               'ROIs1868_summer_s1/s1_80', 'ROIs1868_summer_s1/s1_127', 'ROIs2017_winter_s1/s1_130', 'ROIs1868_summer_s1/s1_17', 'ROIs2017_winter_s1/s1_84']\n","        self.splits['test'] = ['ROIs1158_spring_s1/s1_106', 'ROIs1158_spring_s1/s1_123', 'ROIs1158_spring_s1/s1_140', 'ROIs1158_spring_s1/s1_31', 'ROIs1158_spring_s1/s1_44',\n","                               'ROIs1868_summer_s1/s1_119', 'ROIs1868_summer_s1/s1_73', 'ROIs1970_fall_s1/s1_139', 'ROIs2017_winter_s1/s1_108', 'ROIs2017_winter_s1/s1_63']\n","\n","        self.splits[\"all\"]  = self.splits[\"train\"] + self.splits[\"test\"] + self.splits[\"val\"]\n","        self.split = split\n","\n","        assert split in ['all', 'train', 'val', 'test'], \"Input dataset must be either assigned as all, train, test, or val!\"\n","        assert sample_type in ['pretrain'], \"Input data must be pretrain!\"\n","        assert cloud_masks in [None, 'cloud_cloudshadow_mask', 's2cloudless_map', 's2cloudless_mask'], \"Unknown cloud mask type!\"\n","\n","        self.modalities     = [\"S1\", \"S2\"]\n","        self.cloud_masks    = cloud_masks   # e.g. 'cloud_cloudshadow_mask', 's2cloudless_map', 's2cloudless_mask'\n","        self.sample_type    = sample_type   # e.g. 'pretrain'\n","\n","        self.time_points    = range(1)\n","        self.n_input_t      = 1             # specifies the number of samples, if only part of the time series is used as an input\n","\n","        if self.cloud_masks in ['s2cloudless_map', 's2cloudless_mask']:\n","            self.cloud_detector = S2PixelCloudDetector(threshold=0.4, all_bands=True, average_over=4, dilation_size=2)\n","        else: self.cloud_detector = None\n","\n","        self.paths          = self.get_paths()\n","        self.n_samples      = len(self.paths)\n","\n","        # raise a warning if no data has been found\n","        if not self.n_samples: self.throw_warn()\n","\n","        self.method         = rescale_method\n","\n","    # indexes all patches contained in the current data split\n","    def get_paths(self):  # assuming for the same ROI+num, the patch numbers are the same\n","        print(f'\\nProcessing paths for {self.split} split of region {self.region}')\n","\n","        paths = []\n","        seeds_S1 = natsorted([s1dir for s1dir in os.listdir(self.root_dir) if \"_s1\" in s1dir])\n","        for seed in tqdm(seeds_S1):\n","            rois_S1 = natsorted(os.listdir(os.path.join(self.root_dir, seed)))\n","            for roi in rois_S1:\n","                roi_dir  = os.path.join(self.root_dir, seed, roi)\n","                paths_S1        = natsorted([os.path.join(roi_dir, s1patch) for s1patch in os.listdir(roi_dir)])\n","                paths_S2        = [patch.replace('/s1', '/s2').replace('_s1', '_s2') for patch in paths_S1]\n","                paths_S2_cloudy = [patch.replace('/s1', '/s2_cloudy').replace('_s1', '_s2_cloudy') for patch in paths_S1]\n","\n","                for pdx, _ in enumerate(paths_S1):\n","                    # omit patches that are potentially unpaired\n","                    if not all([os.path.isfile(paths_S1[pdx]), os.path.isfile(paths_S2[pdx]), os.path.isfile(paths_S2_cloudy[pdx])]): continue\n","                    # don't add patch if not belonging to the selected split\n","                    if not any([split_roi in paths_S1[pdx] for split_roi in self.splits[self.split]]): continue\n","                    sample = {\"S1\":         paths_S1[pdx],\n","                              \"S2\":         paths_S2[pdx],\n","                              \"S2_cloudy\":  paths_S2_cloudy[pdx]}\n","                    paths.append(sample)\n","        return paths\n","\n","    def __getitem__(self, pdx):  # get the triplet of patch with ID pdx\n","        s1_tif          = read_tif(os.path.join(self.root_dir, self.paths[pdx]['S1']))\n","        s2_tif          = read_tif(os.path.join(self.root_dir, self.paths[pdx]['S2']))\n","        s2_cloudy_tif   = read_tif(os.path.join(self.root_dir, self.paths[pdx]['S2_cloudy']))\n","        coord           = list(s2_tif.bounds)\n","        s1              = process_SAR(read_img(s1_tif), self.method)\n","        s2              = read_img(s2_tif)           # note: pre-processing happens after cloud detection\n","        s2_cloudy       = read_img(s2_cloudy_tif)    # note: pre-processing happens after cloud detection\n","        mask            = None if not self.cloud_masks else get_cloud_map(s2_cloudy, self.cloud_masks, self.cloud_detector)\n","\n","        sample = {'input': {'S1': s1,\n","                            'S2': process_MS(s2_cloudy, self.method),\n","                            'masks': mask,\n","                            'coverage': np.mean(mask),\n","                            'S1 path': os.path.join(self.root_dir, self.paths[pdx]['S1']),\n","                            'S2 path': os.path.join(self.root_dir, self.paths[pdx]['S2_cloudy']),\n","                            'coord': coord,\n","                            },\n","                    'target': {'S2': process_MS(s2, self.method),\n","                               'S2 path': os.path.join(self.root_dir, self.paths[pdx]['S2']),\n","                               'coord': coord,\n","                                },\n","                    }\n","        return sample\n","\n","    def throw_warn(self):\n","        warnings.warn(\"\"\"No data samples found! Please use the following directory structure:\n","\n","        path/to/your/SEN12MSCR/directory:\n","            ├───ROIs1158_spring_s1\n","            |   ├─s1_1\n","            |   |   |...\n","            |   |   ├─ROIs1158_spring_s1_1_p407.tif\n","            |   |   |...\n","            |    ...\n","            ├───ROIs1158_spring_s2\n","            |   ├─s2_1\n","            |   |   |...\n","            |   |   ├─ROIs1158_spring_s2_1_p407.tif\n","            |   |   |...\n","            |    ...\n","            ├───ROIs1158_spring_s2_cloudy\n","            |   ├─s2_cloudy_1\n","            |   |   |...\n","            |   |   ├─ROIs1158_spring_s2_cloudy_1_p407.tif\n","            |   |   |...\n","            |    ...\n","            ...\n","\n","        Note: Please arrange the dataset in a format as e.g. provided by the script dl_data.sh.\n","        \"\"\")\n","\n","    def __len__(self):\n","        # length of generated list\n","        return self.n_samples"],"metadata":{"id":"GlGEKk1w5gfa"},"execution_count":null,"outputs":[]}]}